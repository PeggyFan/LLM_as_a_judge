# ğŸ§ª GenAI Evaluator Experiment Simulator

> A Streamlit app for assessing how reliable LLMs are as judges in A/B product experiments.

Companies increasingly use LLMs to score product outcomes â€” content quality, UX signals, feature success, etc.  
But LLMs **hallucinate**, **cost money**, and **carry bias** that can distort experiment decisions.

This simulator helps product & AI teams **test evaluator reliability before launch**.

---

## âœ… What This Simulator Measures

| Category | Questions It Answers |
|---------|---------------------|
|ï¸âƒ£ Evaluator Bias | Does the LLM favor Variant A or B? By how much? |
|ï¸âƒ£ Hallucination Rate | How often does it make up incorrect or unsafe claims? |
|ï¸âƒ£ Cost Modeling | How much would it cost to scale evaluations? |
|ï¸âƒ£ Agreement vs Ground Truth | How closely does it match real outcomes? |
|ï¸âƒ£ Trust Score | Should we use this evaluator for product decisions? |

---

## ğŸ¯ Key Use Cases

âœ” Replace slow human QA evaluators  
âœ” Compare multiple LLMs as judges  
âœ” Understand risk before product rollout  
âœ” Optimize experiment strategy and cost  
âœ” Communicate GenAI trustworthiness to stakeholders

---

## ğŸ§© Features at a Glance

- Monte-Carlo A/B experiment simulation  
- Upload or generate LLM evaluation scores
- Cost + hallucination weighted metrics
- Dynamic visualizations:
  - Score distributions
  - Bias impact
  - Hallucination & cost tradeoffs

---

## ğŸ“¦ Getting Started

### Clone the repo
```bash
git clone https://github.com/YOUR_USERNAME/llm-evaluator-simulator.git
cd llm-evaluator-simulator
python3 -m venv .venv
source .venv/bin/activate   # Mac/Linux
# .venv\Scripts\activate    # Windows
pip install -r requirements.txt
streamlit run app.py

/project
 â”œâ”€â”€ app.py                        # Streamlit web app
 â”œâ”€â”€ pipeline.py                   # Generates evaluator scores/bias/hallucinations
 â”œâ”€â”€ llm_evaluator_profile.csv     # Model scoring + cost data
 â”œâ”€â”€ evaluator_bias.json           # Bias by model & variant
 â”œâ”€â”€ hallucination_details.json    # Error samples
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ README.md
